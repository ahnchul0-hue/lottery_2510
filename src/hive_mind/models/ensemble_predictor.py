# ğŸ¤– Ensemble Statistical Predictor
# scikit-learn based ensemble models for lottery prediction

import numpy as np
import pandas as pd
import logging
from typing import List, Dict, Any, Optional, Tuple
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
import joblib
from pathlib import Path

class LotteryEnsemblePredictor:
    """
    scikit-learn ê¸°ë°˜ ì•™ìƒë¸” ì˜ˆì¸¡ê¸°
    
    RandomForest + GradientBoosting + MLP ì¡°í•©
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.models = {}
        self.scaler = StandardScaler()
        self.is_trained = False
        
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # íŠ¹ì„± ì¶”ì¶œê¸°
        self.feature_extractor = LotteryFeatureExtractor()
        
    def initialize(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # RandomForest ëª¨ë¸
            self.models['rf'] = RandomForestClassifier(
                n_estimators=self.config.get('n_estimators', 50),
                max_depth=self.config.get('max_depth', 8),
                random_state=42,
                n_jobs=-1
            )
            
            # GradientBoosting ëª¨ë¸
            self.models['gb'] = GradientBoostingClassifier(
                n_estimators=self.config.get('n_estimators', 50),
                max_depth=self.config.get('max_depth', 6),
                learning_rate=self.config.get('learning_rate', 0.1),
                random_state=42
            )
            
            # MLP ëª¨ë¸
            self.models['mlp'] = MLPClassifier(
                hidden_layer_sizes=(100, 50),
                max_iter=500,
                random_state=42,
                early_stopping=True,
                validation_fraction=0.1
            )
            
            # MultiOutput ë˜í¼ (6ê°œ ë²ˆí˜¸ ë™ì‹œ ì˜ˆì¸¡)
            self.ensemble_models = {
                name: MultiOutputClassifier(model)
                for name, model in self.models.items()
            }
            
            self.logger.info("âœ… Ensemble models initialized")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Model initialization failed: {e}")
            return False
            
    def train(self, historical_data: List[List[int]]) -> bool:
        """ëª¨ë¸ í›ˆë ¨"""
        try:
            if len(historical_data) < 20:
                self.logger.warning("Insufficient data for training")
                return False
                
            self.logger.info(f"Training with {len(historical_data)} historical draws")
            
            # íŠ¹ì„± ì¶”ì¶œ
            X, y = self.feature_extractor.prepare_training_data(historical_data)
            
            if X is None or y is None or len(X) == 0:
                self.logger.error("Feature extraction failed")
                return False
                
            # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
            X_scaled = self.scaler.fit_transform(X)
            
            # ê° ëª¨ë¸ í›ˆë ¨
            for name, model in self.ensemble_models.items():
                self.logger.info(f"Training {name} model...")
                model.fit(X_scaled, y)
                
                # êµì°¨ ê²€ì¦ ì ìˆ˜
                try:
                    scores = cross_val_score(model, X_scaled, y, cv=3, scoring='accuracy')
                    self.logger.info(f"{name} CV accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")
                except:
                    pass  # êµì°¨ ê²€ì¦ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                    
            self.is_trained = True
            self.logger.info("âœ… Model training completed")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Training failed: {e}")
            return False
            
    def predict(self, 
                historical_data: List[List[int]], 
                num_predictions: int = 1,
                machine_type: str = "2í˜¸ê¸°",
                **kwargs) -> List[Dict[str, Any]]:
        """ì˜ˆì¸¡ ì‹¤í–‰"""
        try:
            if not self.is_trained:
                self.logger.warning("Model not trained, using statistical fallback")
                return self._statistical_fallback(historical_data, num_predictions, machine_type)
                
            # íŠ¹ì„± ì¶”ì¶œ
            features = self.feature_extractor.extract_prediction_features(historical_data)
            if features is None:
                return self._statistical_fallback(historical_data, num_predictions, machine_type)
                
            # ìŠ¤ì¼€ì¼ë§
            features_scaled = self.scaler.transform([features])
            
            # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡
            model_predictions = {}
            for name, model in self.ensemble_models.items():
                try:
                    # í™•ë¥  ì˜ˆì¸¡
                    probabilities = model.predict_proba(features_scaled)
                    model_predictions[name] = probabilities
                except:
                    # í™•ë¥  ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ í´ë˜ìŠ¤ ì˜ˆì¸¡
                    pred = model.predict(features_scaled)
                    model_predictions[name] = pred
                    
            # ì•™ìƒë¸” ì˜ˆì¸¡ ê²°í•©
            predictions = self._combine_predictions(
                model_predictions, num_predictions, machine_type
            )
            
            return predictions
            
        except Exception as e:
            self.logger.error(f"âŒ Prediction failed: {e}")
            return self._statistical_fallback(historical_data, num_predictions, machine_type)
            
    def _combine_predictions(self, 
                           model_predictions: Dict[str, Any], 
                           num_predictions: int,
                           machine_type: str) -> List[Dict[str, Any]]:
        """ëª¨ë¸ ì˜ˆì¸¡ ê²°í•©"""
        predictions = []
        
        try:
            # ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜
            weights = {
                'rf': 0.4,
                'gb': 0.35, 
                'mlp': 0.25
            }
            
            # ì•™ìƒë¸” í™•ë¥  ê³„ì‚°
            ensemble_probs = np.zeros(45)  # 1-45ë²ˆ í™•ë¥ 
            
            for name, pred in model_predictions.items():
                weight = weights.get(name, 0.33)
                
                if isinstance(pred, (list, np.ndarray)):
                    # ë‹¤ì°¨ì› ë°°ì—´ ì²˜ë¦¬
                    if hasattr(pred[0], '__len__') and len(pred[0]) > 0:
                        # ê° ìœ„ì¹˜ë³„ í™•ë¥ ì˜ í‰ê· 
                        for pos_probs in pred:
                            if hasattr(pos_probs, '__len__') and len(pos_probs) >= 45:
                                ensemble_probs += weight * np.array(pos_probs[:45]) / 6
                    else:
                        # ë‹¨ìˆœ ì˜ˆì¸¡ê°’
                        for num in pred[0]:
                            if 1 <= num <= 45:
                                ensemble_probs[num-1] += weight / 6
                                
            # í™•ë¥  ì •ê·œí™”
            if ensemble_probs.sum() > 0:
                ensemble_probs /= ensemble_probs.sum()
            else:
                ensemble_probs = np.ones(45) / 45  # ê· ë“± ë¶„í¬
                
            # ê¸°ê³„ë³„ ì „ëµ ì ìš©
            ensemble_probs = self._apply_machine_strategy(ensemble_probs, machine_type)
            
            # ë‹¤ì–‘í•œ ì˜ˆì¸¡ ìƒì„±
            used_combinations = set()
            
            for i in range(num_predictions):
                # Top-k ìƒ˜í”Œë§
                top_k = min(20, len(ensemble_probs))
                top_indices = np.argsort(ensemble_probs)[-top_k:]
                top_probs = ensemble_probs[top_indices]
                
                # ì˜¨ë„ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ë‹¤ì–‘ì„± í™•ë³´
                temperature = 1.0 + (i * 0.2)
                scaled_probs = np.exp(np.log(top_probs + 1e-8) / temperature)
                scaled_probs /= scaled_probs.sum()
                
                # 6ê°œ ë²ˆí˜¸ ì„ íƒ
                selected_numbers = []
                remaining_indices = list(top_indices)
                remaining_probs = scaled_probs.copy()
                
                for _ in range(6):
                    if len(remaining_indices) == 0:
                        break
                        
                    # í™•ë¥  ê¸°ë°˜ ì„ íƒ
                    if remaining_probs.sum() > 0:
                        choice_idx = np.random.choice(
                            len(remaining_indices),
                            p=remaining_probs / remaining_probs.sum()
                        )
                    else:
                        choice_idx = np.random.choice(len(remaining_indices))
                        
                    selected_idx = remaining_indices[choice_idx]
                    number = selected_idx + 1
                    selected_numbers.append(number)
                    
                    # ì„ íƒëœ ë²ˆí˜¸ ì œê±°
                    remaining_indices.pop(choice_idx)
                    remaining_probs = np.delete(remaining_probs, choice_idx)
                    
                # ë¶€ì¡±í•œ ë²ˆí˜¸ ëœë¤ ì±„ìš°ê¸°
                while len(selected_numbers) < 6:
                    available = [n for n in range(1, 46) if n not in selected_numbers]
                    if available:
                        selected_numbers.append(np.random.choice(available))
                    else:
                        break
                        
                selected_numbers = sorted(selected_numbers[:6])
                combo_key = tuple(selected_numbers)
                
                # ì¤‘ë³µ ì²´í¬
                if combo_key not in used_combinations and len(selected_numbers) == 6:
                    used_combinations.add(combo_key)
                    
                    # ì‹ ë¢°ë„ ê³„ì‚°
                    confidence = self._calculate_confidence(selected_numbers, ensemble_probs)
                    
                    predictions.append({
                        'numbers': selected_numbers,
                        'confidence': confidence,
                        'method': 'ensemble_ml',
                        'metadata': {
                            'models_used': list(model_predictions.keys()),
                            'machine_strategy': machine_type,
                            'temperature': temperature
                        }
                    })
                    
            return predictions
            
        except Exception as e:
            self.logger.error(f"âŒ Prediction combination failed: {e}")
            return []
            
    def _apply_machine_strategy(self, probabilities: np.ndarray, machine_type: str) -> np.ndarray:
        """ê¸°ê³„ë³„ ì „ëµ ì ìš©"""
        adjusted_probs = probabilities.copy()
        
        try:
            if machine_type == "1í˜¸ê¸°":
                # ë³´ìˆ˜ì : ì¤‘ê°„ ë²ˆí˜¸ ì„ í˜¸, ê·¹ë‹¨ ë²ˆí˜¸ íšŒí”¼
                for i in range(45):
                    num = i + 1
                    if 15 <= num <= 35:
                        adjusted_probs[i] *= 1.2
                    elif num <= 5 or num >= 40:
                        adjusted_probs[i] *= 0.8
                        
            elif machine_type == "3í˜¸ê¸°":
                # ì°½ì˜ì : í™€ìˆ˜ ì„ í˜¸, ê·¹ë‹¨ ë²ˆí˜¸ ì„ í˜¸
                for i in range(45):
                    num = i + 1
                    if num % 2 == 1:  # í™€ìˆ˜
                        adjusted_probs[i] *= 1.15
                    if num <= 10 or num >= 35:  # ê·¹ë‹¨
                        adjusted_probs[i] *= 1.1
                        
            # 2í˜¸ê¸°ëŠ” ê· í˜•ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ìœ ì§€
            
        except:
            pass  # ì „ëµ ì ìš© ì‹¤íŒ¨í•´ë„ ì›ë³¸ í™•ë¥  ì‚¬ìš©
            
        # í™•ë¥  ì •ê·œí™”
        if adjusted_probs.sum() > 0:
            adjusted_probs /= adjusted_probs.sum()
            
        return adjusted_probs
        
    def _calculate_confidence(self, numbers: List[int], probabilities: np.ndarray) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            # ëª¨ë¸ í™•ë¥  ê¸°ë°˜
            model_conf = sum(probabilities[n-1] for n in numbers) / 6
            
            # í†µê³„ì  ê· í˜• ì ìˆ˜
            odd_count = sum(1 for n in numbers if n % 2 == 1)
            balance_score = 1.0 - abs(odd_count - 3) / 3
            
            # ë²”ìœ„ ë¶„ì‚° ì ìˆ˜
            range_score = (max(numbers) - min(numbers)) / 44  # 0-1 ì •ê·œí™”
            
            # ì¢…í•© ì‹ ë¢°ë„
            confidence = (model_conf * 0.6 + 
                         balance_score * 0.25 + 
                         range_score * 0.15)
            
            return max(0.1, min(0.9, confidence))
            
        except:
            return 0.5
            
    def _statistical_fallback(self, 
                            historical_data: List[List[int]], 
                            num_predictions: int,
                            machine_type: str) -> List[Dict[str, Any]]:
        """í†µê³„ ê¸°ë°˜ fallback ì˜ˆì¸¡"""
        try:
            if not historical_data:
                return self._random_fallback(num_predictions)
                
            # ë²ˆí˜¸ ë¹ˆë„ ë¶„ì„
            frequency = {}
            for draw in historical_data[-20:]:  # ìµœê·¼ 20íšŒ
                for num in draw:
                    frequency[num] = frequency.get(num, 0) + 1
                    
            # ë¹ˆë„ ê¸°ë°˜ í™•ë¥ 
            total_count = sum(frequency.values())
            probabilities = np.array([
                frequency.get(i+1, 0) / max(total_count, 1) 
                for i in range(45)
            ])
            
            # ê¸°ê³„ ì „ëµ ì ìš©
            probabilities = self._apply_machine_strategy(probabilities, machine_type)
            
            # ì˜ˆì¸¡ ìƒì„±
            predictions = []
            for _ in range(num_predictions):
                # ê°€ì¤‘ ëœë¤ ì„ íƒ
                if probabilities.sum() > 0:
                    selected = np.random.choice(
                        45, size=6, replace=False,
                        p=probabilities / probabilities.sum()
                    )
                    numbers = sorted([int(x) + 1 for x in selected])
                else:
                    numbers = sorted(np.random.choice(range(1, 46), 6, replace=False))
                    
                predictions.append({
                    'numbers': numbers,
                    'confidence': 0.4,
                    'method': 'statistical_fallback',
                    'metadata': {'machine_type': machine_type}
                })
                
            return predictions
            
        except:
            return self._random_fallback(num_predictions)
            
    def _random_fallback(self, num_predictions: int) -> List[Dict[str, Any]]:
        """ëœë¤ fallback"""
        predictions = []
        for _ in range(num_predictions):
            numbers = sorted(np.random.choice(range(1, 46), 6, replace=False))
            predictions.append({
                'numbers': numbers.tolist(),
                'confidence': 0.2,
                'method': 'random_fallback',
                'metadata': {}
            })
        return predictions
        
    def save_models(self, model_dir: str):
        """ëª¨ë¸ ì €ì¥"""
        model_path = Path(model_dir)
        model_path.mkdir(parents=True, exist_ok=True)
        
        try:
            # ì•™ìƒë¸” ëª¨ë¸ ì €ì¥
            joblib.dump(self.ensemble_models, model_path / 'ensemble_models.pkl')
            joblib.dump(self.scaler, model_path / 'scaler.pkl')
            
            # í›ˆë ¨ ìƒíƒœ ì €ì¥
            metadata = {
                'is_trained': self.is_trained,
                'config': self.config
            }
            joblib.dump(metadata, model_path / 'metadata.pkl')
            
            self.logger.info(f"Models saved to {model_path}")
            
        except Exception as e:
            self.logger.error(f"âŒ Model saving failed: {e}")
            
    def load_models(self, model_dir: str):
        """ëª¨ë¸ ë¡œë“œ"""
        model_path = Path(model_dir)
        
        try:
            if (model_path / 'ensemble_models.pkl').exists():
                self.ensemble_models = joblib.load(model_path / 'ensemble_models.pkl')
                self.scaler = joblib.load(model_path / 'scaler.pkl')
                
                metadata = joblib.load(model_path / 'metadata.pkl')
                self.is_trained = metadata.get('is_trained', False)
                
                self.logger.info(f"Models loaded from {model_path}")
                return True
            else:
                self.logger.warning(f"No saved models found in {model_path}")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ Model loading failed: {e}")
            return False

class LotteryFeatureExtractor:
    """ë¡œë˜ íŠ¹ì„± ì¶”ì¶œê¸°"""
    
    def prepare_training_data(self, historical_data: List[List[int]]) -> Tuple[np.ndarray, np.ndarray]:
        """í›ˆë ¨ìš© ë°ì´í„° ì¤€ë¹„"""
        try:
            if len(historical_data) < 10:
                return None, None
                
            X, y = [], []
            
            for i in range(5, len(historical_data)):
                # ê³¼ê±° 5íšŒ ë°ì´í„°ë¡œ íŠ¹ì„± ìƒì„±
                recent_draws = historical_data[i-5:i]
                features = self._extract_features(recent_draws)
                
                # íƒ€ê²Ÿì€ ë‹¤ìŒ ì¶”ì²¨
                target = historical_data[i]
                
                if features is not None and len(target) == 6:
                    X.append(features)
                    # íƒ€ê²Ÿì„ 6ê°œ ë³„ë„ ë¶„ë¥˜ ë¬¸ì œë¡œ ë³€í™˜ (1-45 í´ë˜ìŠ¤)
                    y.append([num - 1 for num in target])  # 0-based
                    
            return np.array(X), np.array(y)
            
        except Exception as e:
            logging.error(f"Training data preparation failed: {e}")
            return None, None
            
    def extract_prediction_features(self, historical_data: List[List[int]]) -> Optional[np.ndarray]:
        """ì˜ˆì¸¡ìš© íŠ¹ì„± ì¶”ì¶œ"""
        try:
            if len(historical_data) < 5:
                return None
                
            recent_draws = historical_data[-5:]  # ìµœê·¼ 5íšŒ
            return self._extract_features(recent_draws)
            
        except Exception as e:
            logging.error(f"Feature extraction failed: {e}")
            return None
            
    def _extract_features(self, draws: List[List[int]]) -> Optional[np.ndarray]:
        """íŠ¹ì„± ì¶”ì¶œ ë¡œì§"""
        try:
            features = []
            
            # 1. ë²ˆí˜¸ ë¹ˆë„ (1-45)
            frequency = {i: 0 for i in range(1, 46)}
            for draw in draws:
                for num in draw:
                    if 1 <= num <= 45:
                        frequency[num] += 1
                        
            features.extend([frequency[i] for i in range(1, 46)])
            
            # 2. í†µê³„ì  íŠ¹ì„±
            for draw in draws:
                if len(draw) >= 6:
                    sorted_nums = sorted(draw[:6])
                    
                    # í™€ì§ ë¹„ìœ¨
                    odd_count = sum(1 for n in sorted_nums if n % 2 == 1)
                    features.append(odd_count / 6)
                    
                    # ê³ ì € ë¹„ìœ¨  
                    high_count = sum(1 for n in sorted_nums if n >= 23)
                    features.append(high_count / 6)
                    
                    # ë²ˆí˜¸ í•©
                    features.append(sum(sorted_nums))
                    
                    # ë²”ìœ„
                    features.append(max(sorted_nums) - min(sorted_nums))
                    
                    # ì—°ì† ë²ˆí˜¸ ê°œìˆ˜
                    consecutive = 0
                    for i in range(len(sorted_nums) - 1):
                        if sorted_nums[i+1] - sorted_nums[i] == 1:
                            consecutive += 1
                    features.append(consecutive)
                else:
                    features.extend([0, 0, 0, 0, 0])  # ê¸°ë³¸ê°’
                    
            # 3. ê°„ê²© íŒ¨í„´ (ìµœê·¼ ì¶”ì²¨)
            if draws and len(draws[-1]) >= 6:
                last_draw = sorted(draws[-1][:6])
                gaps = [last_draw[i+1] - last_draw[i] for i in range(5)]
                features.extend(gaps)
            else:
                features.extend([0, 0, 0, 0, 0])
                
            return np.array(features)
            
        except Exception as e:
            logging.error(f"Feature extraction error: {e}")
            return None