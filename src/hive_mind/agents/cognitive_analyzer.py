# ğŸ§  Cognitive Analyzer Agent - Domain Knowledge & Reasoning Specialist
# Advanced cognitive analysis with domain expertise and explainable AI

import json
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import logging
import re
from collections import defaultdict, Counter

from .base import BaseAgent, AgentCapabilities, AgentStatus

class CognitiveAnalyzerAgent(BaseAgent):
    """
    ì¸ì§€ ë¶„ì„ ì—ì´ì „íŠ¸
    
    ë„ë©”ì¸ ì „ë¬¸ê°€ì˜ ë£°ê³¼ ë§¥ë½ì  íŒë‹¨ì„ ë‹´ë‹¹:
    - ê·œì¹™ ê¸°ë°˜ ì§€ì‹ê³¼ ë§¥ë½ì  íŒë‹¨ ìˆ˜í–‰
    - ë‹¤ë¥¸ ì—ì´ì „íŠ¸ë“¤ì˜ ê²°ê³¼ì— ì„¤ëª…ì„ ë‹¬ê±°ë‚˜ ëª¨ìˆœ ë°œê²¬ ë° ì¡°ì •
    - ì¸ê°„ì²˜ëŸ¼ í•´ì„í•˜ê³  ì „ëµì„ ë„ì¶œí•˜ëŠ” ì¸ì§€ì  ì¶”ë¡ 
    - ì„¤ëª… ê°€ëŠ¥í•œ AI (XAI) ê¸°ë²• ì ìš©
    """
    
    def __init__(self, agent_id: str, memory_manager, message_bus, config: Dict[str, Any]):
        super().__init__(agent_id, memory_manager, message_bus, config)
        
        self.capabilities = [
            AgentCapabilities.COGNITIVE_REASONING,
            AgentCapabilities.DOMAIN_EXPERTISE,
            AgentCapabilities.EXPLANATION_GENERATION
        ]
        
        # ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤
        self.domain_knowledge = self._initialize_domain_knowledge()
        self.cognitive_rules = self._initialize_cognitive_rules()
        
        # ë¶„ì„ ì„¤ì •
        self.confidence_threshold = config.get('confidence_threshold', 0.7)
        self.explanation_detail_level = config.get('explanation_detail_level', 'detailed')
        
        # ì¸ì§€ ë©”ëª¨ë¦¬
        self.pattern_memory = {}
        self.anomaly_detection_rules = {}
        self.explanation_templates = {}
        
    async def initialize(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        self.logger.info(f"ğŸ§  Initializing Cognitive Analyzer Agent {self.agent_id}")
        
        try:
            # ë„ë©”ì¸ ì§€ì‹ ë¡œë“œ
            await self._load_domain_knowledge()
            
            # ì¸ì§€ ê·œì¹™ ì„¤ì •
            await self._setup_cognitive_rules()
            
            # ì„¤ëª… í…œí”Œë¦¿ ì´ˆê¸°í™”
            await self._initialize_explanation_templates()
            
            # ê³¼ê±° íŒ¨í„´ í•™ìŠµ
            await self._learn_historical_patterns()
            
            self.status = AgentStatus.ACTIVE
            self.logger.info("âœ… Cognitive Analyzer Agent initialized")
            
        except Exception as e:
            self.status = AgentStatus.ERROR
            self.logger.error(f"âŒ Failed to initialize Cognitive Analyzer: {e}")
            raise
            
    def _initialize_domain_knowledge(self) -> Dict[str, Any]:
        """ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        return {
            'number_properties': {
                'primes': [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43],
                'fibonacci': [1, 1, 2, 3, 5, 8, 13, 21, 34],
                'perfect_squares': [1, 4, 9, 16, 25, 36],
                'lucky_numbers': [7, 11, 13, 21, 23, 33],  # ë¬¸í™”ì  í–‰ìš´ ë²ˆí˜¸
                'unlucky_numbers': [4, 14, 24, 34, 44]     # ë¬¸í™”ì  ë¶ˆìš´ ë²ˆí˜¸ (í•œêµ­)
            },
            'statistical_norms': {
                'odd_even_balance': {'min': 2, 'max': 4, 'ideal': 3},
                'high_low_balance': {'min': 2, 'max': 4, 'ideal': 3},
                'total_sum_range': {'min': 21, 'max': 270, 'typical': (105, 165)},
                'ac_value_range': {'min': 0, 'max': 15, 'typical': (8, 13)},
                'last_digit_sum_range': {'min': 0, 'max': 54, 'typical': (15, 25)}
            },
            'machine_personalities': {
                '1í˜¸ê¸°': {
                    'traits': ['conservative', 'reliable', 'high_frequency_bias'],
                    'typical_patterns': ['balanced_distribution', 'moderate_ac_values'],
                    'avoidance': ['extreme_combinations', 'very_low_sums']
                },
                '2í˜¸ê¸°': {
                    'traits': ['balanced', 'harmonious', 'perfectionist'],
                    'typical_patterns': ['even_distribution', 'optimal_ratios'],
                    'avoidance': ['unbalanced_sections', 'extreme_digit_sums']
                },
                '3í˜¸ê¸°': {
                    'traits': ['creative', 'diverse', 'odd_preference'],
                    'typical_patterns': ['unique_combinations', 'pattern_breaking'],
                    'avoidance': ['consecutive_heavy', 'conservative_ranges']
                }
            }
        }
        
    def _initialize_cognitive_rules(self) -> Dict[str, Any]:
        """ì¸ì§€ ê·œì¹™ ì´ˆê¸°í™”"""
        return {
            'validation_rules': [
                {
                    'name': 'extreme_imbalance_check',
                    'condition': lambda numbers: self._check_extreme_imbalance(numbers),
                    'severity': 'high',
                    'message': 'ê·¹ë‹¨ì ì¸ í™€ì§ ë˜ëŠ” ê³ ì € ë¶ˆê· í˜• ê°ì§€'
                },
                {
                    'name': 'unusual_sum_check', 
                    'condition': lambda numbers: sum(numbers) < 50 or sum(numbers) > 250,
                    'severity': 'medium',
                    'message': 'ë¹„ì •ìƒì ì¸ ì´í•© ë²”ìœ„'
                },
                {
                    'name': 'consecutive_overflow_check',
                    'condition': lambda numbers: self._count_consecutive_numbers(numbers) > 3,
                    'severity': 'medium',
                    'message': 'ê³¼ë„í•œ ì—°ì† ë²ˆí˜¸ í¬í•¨'
                },
                {
                    'name': 'recent_duplicate_check',
                    'condition': lambda numbers: self._check_recent_duplicates(numbers),
                    'severity': 'low',
                    'message': 'ìµœê·¼ íšŒì°¨ì™€ ë†’ì€ ìœ ì‚¬ì„±'
                }
            ],
            'enhancement_rules': [
                {
                    'name': 'diversity_enhancement',
                    'condition': lambda numbers: len(set(n % 10 for n in numbers)) < 4,
                    'action': 'suggest_digit_diversification',
                    'message': 'ëìë¦¬ ë‹¤ì–‘ì„± ì¦ëŒ€ ê¶Œì¥'
                },
                {
                    'name': 'machine_alignment',
                    'condition': lambda numbers, machine: self._check_machine_alignment(numbers, machine),
                    'action': 'apply_machine_specific_adjustment',
                    'message': 'í˜¸ê¸°ë³„ íŠ¹ì„± alignment ì¡°ì •'
                }
            ]
        }
        
    async def process_prediction(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¸ì§€ ë¶„ì„ ì²˜ë¦¬"""
        machine_type = task_data['machine_type']
        sets_count = task_data['sets_count']
        
        self.logger.info(f"ğŸ§  Processing cognitive analysis for {machine_type}")
        
        try:
            # 1. ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
            context_analysis = await self._analyze_context(machine_type)
            
            # 2. ì¸ì§€ ê¸°ë°˜ ì˜ˆì¸¡ ìƒì„±
            predictions = []
            for i in range(sets_count):
                cognitive_result = await self._generate_cognitive_prediction(
                    context_analysis, machine_type, i
                )
                predictions.append(cognitive_result)
                
            # 3. ë©”íƒ€ ë¶„ì„ ë° ì„¤ëª… ìƒì„±
            meta_analysis = await self._generate_meta_analysis(
                predictions, machine_type, context_analysis
            )
            
            return {
                'agent_id': self.agent_id,
                'agent_type': 'cognitive_analyzer',
                'predictions': predictions,
                'context_analysis': context_analysis,
                'meta_analysis': meta_analysis,
                'avg_confidence': np.mean([p['confidence_score'] for p in predictions])
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Cognitive analysis failed: {e}")
            raise
            
    async def analyze_other_agents_results(self, 
                                         agent_results: Dict[str, Any],
                                         task_data: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ê²°ê³¼ ë¶„ì„ ë° ì¡°ì •"""
        machine_type = task_data['machine_type']
        
        analysis = {
            'consistency_check': {},
            'anomaly_detection': {},
            'recommendations': [],
            'explanations': []
        }
        
        # ê° ì—ì´ì „íŠ¸ ê²°ê³¼ ê²€ì¦
        for agent_id, result in agent_results.items():
            if 'predictions' in result:
                for prediction in result['predictions']:
                    numbers = prediction['numbers']
                    
                    # ì¸ì§€ ê·œì¹™ ì ìš©
                    validation_result = await self._validate_with_cognitive_rules(
                        numbers, machine_type
                    )
                    
                    analysis['consistency_check'][agent_id] = validation_result
                    
                    # ì´ìƒ íƒì§€
                    anomalies = await self._detect_anomalies(
                        numbers, machine_type, agent_id
                    )
                    
                    if anomalies:
                        analysis['anomaly_detection'][agent_id] = anomalies
                        
        # ì¢…í•© ì¶”ì²œì‚¬í•­ ìƒì„±
        analysis['recommendations'] = await self._generate_recommendations(
            agent_results, machine_type
        )
        
        # ì„¤ëª… ìƒì„±
        analysis['explanations'] = await self._generate_comprehensive_explanations(
            agent_results, machine_type, analysis
        )
        
        return analysis
        
    async def get_specialization_info(self) -> Dict[str, Any]:
        """íŠ¹í™” ì •ë³´ ë°˜í™˜"""
        return {
            'specialization': 'Cognitive Reasoning & Domain Expertise',
            'capabilities': [
                'Rule-based validation',
                'Anomaly detection', 
                'Contextual reasoning',
                'Explanation generation',
                'Machine-specific analysis'
            ],
            'domain_knowledge_areas': list(self.domain_knowledge.keys()),
            'cognitive_rules_count': len(self.cognitive_rules['validation_rules']),
            'explanation_templates': len(self.explanation_templates),
            'confidence_threshold': self.confidence_threshold
        }
        
    async def _analyze_context(self, machine_type: str) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        
        # ìµœê·¼ ë°ì´í„° ë¡œë“œ
        recent_data = await self.memory_manager.get_lottery_data(
            machine_type=machine_type, limit=20
        )
        
        context = {
            'machine_personality': self.domain_knowledge['machine_personalities'][machine_type],
            'recent_trends': {},
            'seasonal_factors': {},
            'anomaly_indicators': {}
        }
        
        if recent_data:
            # ìµœê·¼ íŠ¸ë Œë“œ ë¶„ì„
            context['recent_trends'] = self._analyze_recent_trends(recent_data)
            
            # ê³„ì ˆì  ìš”ì¸ (ê°„ë‹¨í•œ ì‹œê°„ ê¸°ë°˜)
            context['seasonal_factors'] = self._analyze_seasonal_factors()
            
            # ì´ìƒ ì§€í‘œ
            context['anomaly_indicators'] = self._detect_context_anomalies(recent_data)
            
        return context
        
    def _analyze_recent_trends(self, recent_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ìµœê·¼ íŠ¸ë Œë“œ ë¶„ì„"""
        
        trends = {
            'sum_trend': 'stable',
            'odd_even_trend': 'balanced',
            'ac_trend': 'normal',
            'frequency_shifts': []
        }
        
        if len(recent_data) >= 10:
            # ì´í•© íŠ¸ë Œë“œ
            recent_sums = [r['ì´í•©'] for r in recent_data[-10:]]
            if recent_sums[-1] > np.mean(recent_sums[:-1]) + np.std(recent_sums[:-1]):
                trends['sum_trend'] = 'increasing'
            elif recent_sums[-1] < np.mean(recent_sums[:-1]) - np.std(recent_sums[:-1]):
                trends['sum_trend'] = 'decreasing'
                
            # í™€ì§ íŠ¸ë Œë“œ
            recent_odd_counts = []
            for r in recent_data[-5:]:
                odd_count = sum(1 for n in r['1ë“±_ë‹¹ì²¨ë²ˆí˜¸'] if n % 2 == 1)
                recent_odd_counts.append(odd_count)
                
            if np.mean(recent_odd_counts) > 3.5:
                trends['odd_even_trend'] = 'odd_favoring'
            elif np.mean(recent_odd_counts) < 2.5:
                trends['odd_even_trend'] = 'even_favoring'
                
            # ACê°’ íŠ¸ë Œë“œ
            recent_ac = [r['ACê°’'] for r in recent_data[-5:]]
            if np.mean(recent_ac) > 12:
                trends['ac_trend'] = 'high_complexity'
            elif np.mean(recent_ac) < 8:
                trends['ac_trend'] = 'low_complexity'
                
        return trends
        
    def _analyze_seasonal_factors(self) -> Dict[str, Any]:
        """ê³„ì ˆì  ìš”ì¸ ë¶„ì„"""
        now = datetime.now()
        
        seasonal_factors = {
            'month_factor': now.month,
            'season': self._get_season(now.month),
            'cultural_events': self._check_cultural_events(now),
            'psychological_bias': 'none'
        }
        
        # ì—°ë§ì—°ì‹œ íš¨ê³¼
        if now.month in [12, 1]:
            seasonal_factors['psychological_bias'] = 'year_end_optimism'
        elif now.month in [6, 7]:
            seasonal_factors['psychological_bias'] = 'summer_relaxation'
            
        return seasonal_factors
        
    def _get_season(self, month: int) -> str:
        """ê³„ì ˆ ë°˜í™˜"""
        if month in [3, 4, 5]:
            return 'spring'
        elif month in [6, 7, 8]:
            return 'summer'
        elif month in [9, 10, 11]:
            return 'autumn'
        else:
            return 'winter'
            
    def _check_cultural_events(self, date: datetime) -> List[str]:
        """ë¬¸í™”ì  ì´ë²¤íŠ¸ í™•ì¸"""
        events = []
        
        # ê°„ë‹¨í•œ ì´ë²¤íŠ¸ ì²´í¬
        if date.month == 2 and 10 <= date.day <= 20:
            events.append('lunar_new_year')
        elif date.month == 12 and date.day >= 20:
            events.append('christmas_season')
            
        return events
        
    def _detect_context_anomalies(self, recent_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ì´ìƒ íƒì§€"""
        anomalies = {
            'unusual_patterns': [],
            'statistical_outliers': [],
            'sequence_breaks': []
        }
        
        if len(recent_data) >= 5:
            # í†µê³„ì  ì´ìƒê°’
            recent_sums = [r['ì´í•©'] for r in recent_data[-5:]]
            mean_sum = np.mean(recent_sums)
            std_sum = np.std(recent_sums)
            
            for i, sum_val in enumerate(recent_sums):
                if abs(sum_val - mean_sum) > 2 * std_sum:
                    anomalies['statistical_outliers'].append({
                        'type': 'sum_outlier',
                        'value': sum_val,
                        'position': i,
                        'severity': 'high' if abs(sum_val - mean_sum) > 3 * std_sum else 'medium'
                    })
                    
        return anomalies
        
    async def _generate_cognitive_prediction(self,
                                          context_analysis: Dict[str, Any],
                                          machine_type: str,
                                          prediction_index: int) -> Dict[str, Any]:
        """ì¸ì§€ ê¸°ë°˜ ì˜ˆì¸¡ ìƒì„±"""
        
        # ê¸°ë³¸ ë²ˆí˜¸ í’€ ìƒì„± (ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜)
        base_numbers = await self._generate_base_number_pool(machine_type, context_analysis)
        
        # ì¸ì§€ ê·œì¹™ ì ìš©í•˜ì—¬ ë²ˆí˜¸ ì„ íƒ
        selected_numbers = await self._apply_cognitive_selection(
            base_numbers, machine_type, prediction_index, context_analysis
        )
        
        # ê²€ì¦ ë° ì¡°ì •
        validated_numbers = await self._validate_and_adjust(
            selected_numbers, machine_type, context_analysis
        )
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence_score = await self._calculate_cognitive_confidence(
            validated_numbers, machine_type, context_analysis
        )
        
        # ì„¤ëª… ìƒì„±
        explanation = await self._generate_prediction_explanation(
            validated_numbers, machine_type, context_analysis
        )
        
        return {
            'set_number': prediction_index + 1,
            'numbers': sorted(validated_numbers),
            'confidence_score': confidence_score,
            'cognitive_reasoning': explanation,
            'selection_method': 'cognitive_domain_knowledge',
            'context_factors': self._extract_key_context_factors(context_analysis)
        }
        
    async def _generate_base_number_pool(self,
                                       machine_type: str,
                                       context_analysis: Dict[str, Any]) -> List[int]:
        """ê¸°ë³¸ ë²ˆí˜¸ í’€ ìƒì„±"""
        
        personality = context_analysis['machine_personality']
        number_pool = list(range(1, 46))
        
        # í˜¸ê¸°ë³„ ì„ í˜¸ë„ ì ìš©
        if machine_type == '1í˜¸ê¸°':
            # ì‹ ì¤‘í•œ ì „ëµê°€: ì¤‘ê°„~ê³ ë¹ˆë„ ë²ˆí˜¸ ì„ í˜¸
            preferred_ranges = [10, 15, 20, 25, 30, 35, 40]
            weights = [2 if n in preferred_ranges else 1 for n in number_pool]
            
        elif machine_type == '2í˜¸ê¸°':
            # ì™„ë²½í•œ ì¡°í™”: ê· í˜•ìˆëŠ” ë¶„í¬
            weights = [1.5 if 15 <= n <= 35 else 1 for n in number_pool]
            
        elif machine_type == '3í˜¸ê¸°':
            # ì°½ì¡°ì  í˜ì‹ : í™€ìˆ˜ ë° íŠ¹ìˆ˜ ë²ˆí˜¸ ì„ í˜¸
            special_nums = set(self.domain_knowledge['number_properties']['primes'] + 
                             self.domain_knowledge['number_properties']['fibonacci'])
            weights = [1.8 if (n % 2 == 1 or n in special_nums) else 1 for n in number_pool]
            
        else:
            weights = [1] * len(number_pool)
            
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë²ˆí˜¸ í’€ ìƒì„±
        weighted_pool = []
        for num, weight in zip(number_pool, weights):
            weighted_pool.extend([num] * int(weight))
            
        return weighted_pool
        
    async def _apply_cognitive_selection(self,
                                       base_pool: List[int],
                                       machine_type: str,
                                       prediction_index: int,
                                       context_analysis: Dict[str, Any]) -> List[int]:
        """ì¸ì§€ì  ì„ íƒ ì ìš©"""
        
        selected = []
        available_pool = base_pool.copy()
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ë²ˆí˜¸ë“¤
        priority_numbers = self._identify_priority_numbers(context_analysis, machine_type)
        
        # ìš°ì„ ìˆœìœ„ ë²ˆí˜¸ ì¤‘ í•˜ë‚˜ ì„ íƒ
        if priority_numbers:
            priority_choice = np.random.choice(priority_numbers)
            selected.append(priority_choice)
            available_pool = [n for n in available_pool if n != priority_choice]
            
        # ë‚˜ë¨¸ì§€ ë²ˆí˜¸ë“¤ ì„ íƒ (ë‹¤ì–‘í•œ ì¸ì§€ ì „ëµ ì ìš©)
        while len(selected) < 6 and available_pool:
            
            # ê· í˜• ê³ ë ¤
            if len(selected) >= 3:
                next_number = self._select_for_balance(selected, available_pool, machine_type)
            else:
                # ì´ˆê¸°ì—ëŠ” ë‹¤ì–‘ì„± ì¤‘ì‹¬
                next_number = self._select_for_diversity(selected, available_pool)
                
            selected.append(next_number)
            available_pool = [n for n in available_pool if n != next_number]
            
        return selected[:6]
        
    def _identify_priority_numbers(self,
                                 context_analysis: Dict[str, Any],
                                 machine_type: str) -> List[int]:
        """ìš°ì„ ìˆœìœ„ ë²ˆí˜¸ ì‹ë³„"""
        
        priority_numbers = []
        trends = context_analysis['recent_trends']
        
        # íŠ¸ë Œë“œ ê¸°ë°˜ ìš°ì„ ìˆœìœ„
        if trends['sum_trend'] == 'increasing':
            priority_numbers.extend([25, 30, 35, 40])  # ë†’ì€ ë²ˆí˜¸ë“¤
        elif trends['sum_trend'] == 'decreasing':
            priority_numbers.extend([5, 10, 15, 20])   # ë‚®ì€ ë²ˆí˜¸ë“¤
            
        if trends['odd_even_trend'] == 'odd_favoring':
            priority_numbers.extend([n for n in range(1, 46) if n % 2 == 1][:10])
        elif trends['odd_even_trend'] == 'even_favoring':
            priority_numbers.extend([n for n in range(1, 46) if n % 2 == 0][:10])
            
        # ë¬¸í™”ì  ì„ í˜¸ë„
        cultural_events = context_analysis['seasonal_factors']['cultural_events']
        if 'lunar_new_year' in cultural_events:
            priority_numbers.extend([8, 18, 28, 38])  # í–‰ìš´ ë²ˆí˜¸ (8)
            
        return list(set(priority_numbers))
        
    def _select_for_balance(self, selected: List[int], available: List[int], machine_type: str) -> int:
        """ê· í˜•ì„ ìœ„í•œ ë²ˆí˜¸ ì„ íƒ"""
        
        # í˜„ì¬ ì„ íƒëœ ë²ˆí˜¸ë“¤ì˜ íŠ¹ì„± ë¶„ì„
        selected_odd = sum(1 for n in selected if n % 2 == 1)
        selected_high = sum(1 for n in selected if n >= 23)
        
        # ê· í˜•ì„ ìœ„í•œ í•„í„°ë§
        candidates = available.copy()
        
        # í™€ì§ ê· í˜•
        if selected_odd < len(selected) / 2:  # í™€ìˆ˜ê°€ ì ìœ¼ë©´
            candidates = [n for n in candidates if n % 2 == 1]
        elif selected_odd > len(selected) / 2:  # í™€ìˆ˜ê°€ ë§ìœ¼ë©´
            candidates = [n for n in candidates if n % 2 == 0]
            
        # ê³ ì € ê· í˜•
        if selected_high < len(selected) / 2:  # ê³ ìˆ˜ê°€ ì ìœ¼ë©´
            candidates = [n for n in candidates if n >= 23]
        elif selected_high > len(selected) / 2:  # ê³ ìˆ˜ê°€ ë§ìœ¼ë©´
            candidates = [n for n in candidates if n < 23]
            
        if not candidates:
            candidates = available
            
        return np.random.choice(candidates)
        
    def _select_for_diversity(self, selected: List[int], available: List[int]) -> int:
        """ë‹¤ì–‘ì„±ì„ ìœ„í•œ ë²ˆí˜¸ ì„ íƒ"""
        
        if not selected:
            return np.random.choice(available)
            
        # ê¸°ì¡´ ì„ íƒê³¼ ê±°ë¦¬ ê³„ì‚°
        diversity_scores = []
        for candidate in available:
            min_distance = min(abs(candidate - s) for s in selected)
            diversity_scores.append(min_distance)
            
        # ë†’ì€ ë‹¤ì–‘ì„± ì ìˆ˜ë¥¼ ê°€ì§„ ë²ˆí˜¸ë“¤ ì¤‘ ì„ íƒ
        max_diversity = max(diversity_scores)
        best_candidates = [
            available[i] for i, score in enumerate(diversity_scores)
            if score >= max_diversity * 0.8
        ]
        
        return np.random.choice(best_candidates)
        
    async def _validate_and_adjust(self,
                                 numbers: List[int],
                                 machine_type: str,
                                 context_analysis: Dict[str, Any]) -> List[int]:
        """ê²€ì¦ ë° ì¡°ì •"""
        
        validated_numbers = numbers.copy()
        
        # ì¸ì§€ ê·œì¹™ ê²€ì¦
        for rule in self.cognitive_rules['validation_rules']:
            if rule['condition'](validated_numbers):
                self.logger.warning(f"âš ï¸  Cognitive rule triggered: {rule['message']}")
                
                # ì¡°ì • ë¡œì§ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
                if rule['name'] == 'extreme_imbalance_check':
                    validated_numbers = self._adjust_for_balance(validated_numbers)
                elif rule['name'] == 'consecutive_overflow_check':
                    validated_numbers = self._reduce_consecutive_numbers(validated_numbers)
                    
        return validated_numbers
        
    def _adjust_for_balance(self, numbers: List[int]) -> List[int]:
        """ê· í˜• ì¡°ì •"""
        adjusted = numbers.copy()
        
        odd_count = sum(1 for n in adjusted if n % 2 == 1)
        
        if odd_count <= 1:  # í™€ìˆ˜ê°€ ë„ˆë¬´ ì ìŒ
            # ì§ìˆ˜ í•˜ë‚˜ë¥¼ í™€ìˆ˜ë¡œ êµì²´
            even_numbers = [n for n in adjusted if n % 2 == 0]
            if even_numbers:
                replace_target = np.random.choice(even_numbers)
                adjusted.remove(replace_target)
                
                # í™€ìˆ˜ë¡œ êµì²´ (ë¹„ìŠ·í•œ ë²”ìœ„)
                replacement_odd = replace_target + 1 if replace_target < 45 else replace_target - 1
                if replacement_odd % 2 == 1 and replacement_odd not in adjusted:
                    adjusted.append(replacement_odd)
                else:
                    # ëŒ€ì•ˆ í™€ìˆ˜ ì°¾ê¸°
                    for candidate in range(1, 46, 2):
                        if candidate not in adjusted:
                            adjusted.append(candidate)
                            break
                            
        elif odd_count >= 5:  # í™€ìˆ˜ê°€ ë„ˆë¬´ ë§ìŒ
            # í™€ìˆ˜ í•˜ë‚˜ë¥¼ ì§ìˆ˜ë¡œ êµì²´
            odd_numbers = [n for n in adjusted if n % 2 == 1]
            replace_target = np.random.choice(odd_numbers)
            adjusted.remove(replace_target)
            
            # ì§ìˆ˜ë¡œ êµì²´
            replacement_even = replace_target + 1 if replace_target < 45 else replace_target - 1
            if replacement_even % 2 == 0 and replacement_even not in adjusted:
                adjusted.append(replacement_even)
            else:
                for candidate in range(2, 46, 2):
                    if candidate not in adjusted:
                        adjusted.append(candidate)
                        break
                        
        return adjusted
        
    def _reduce_consecutive_numbers(self, numbers: List[int]) -> List[int]:
        """ì—°ì† ë²ˆí˜¸ ê°ì†Œ"""
        sorted_numbers = sorted(numbers)
        adjusted = []
        
        i = 0
        consecutive_count = 1
        
        while i < len(sorted_numbers):
            current = sorted_numbers[i]
            adjusted.append(current)
            
            # ì—°ì† ë²ˆí˜¸ ì²´í¬
            while (i + 1 < len(sorted_numbers) and 
                   sorted_numbers[i + 1] == sorted_numbers[i] + 1):
                consecutive_count += 1
                if consecutive_count <= 3:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ì—°ì† í—ˆìš©
                    i += 1
                    adjusted.append(sorted_numbers[i])
                else:
                    # ì—°ì† ë²ˆí˜¸ ê±´ë„ˆë›°ê³  ë‹¤ë¥¸ ë²ˆí˜¸ë¡œ ëŒ€ì²´
                    i += 1
                    replacement = self._find_replacement_number(adjusted, sorted_numbers[i:])
                    if replacement:
                        adjusted.append(replacement)
                    break
                    
            consecutive_count = 1
            i += 1
            
        return adjusted[:6]
        
    def _find_replacement_number(self, current: List[int], remaining: List[int]) -> Optional[int]:
        """ëŒ€ì²´ ë²ˆí˜¸ ì°¾ê¸°"""
        all_numbers = set(range(1, 46))
        used_numbers = set(current + remaining)
        available = list(all_numbers - used_numbers)
        
        if available:
            return np.random.choice(available)
        return None
        
    def _check_extreme_imbalance(self, numbers: List[int]) -> bool:
        """ê·¹ë‹¨ì  ë¶ˆê· í˜• ì²´í¬"""
        odd_count = sum(1 for n in numbers if n % 2 == 1)
        high_count = sum(1 for n in numbers if n >= 23)
        
        return odd_count <= 1 or odd_count >= 5 or high_count <= 1 or high_count >= 5
        
    def _count_consecutive_numbers(self, numbers: List[int]) -> int:
        """ì—°ì† ë²ˆí˜¸ ê°œìˆ˜ ì„¸ê¸°"""
        sorted_numbers = sorted(numbers)
        consecutive_count = 0
        
        for i in range(len(sorted_numbers) - 1):
            if sorted_numbers[i + 1] - sorted_numbers[i] == 1:
                consecutive_count += 1
                
        return consecutive_count
        
    def _check_recent_duplicates(self, numbers: List[int]) -> bool:
        """ìµœê·¼ íšŒì°¨ ì¤‘ë³µ ì²´í¬ (ë‹¨ìˆœ êµ¬í˜„)"""
        # ì‹¤ì œë¡œëŠ” ë©”ëª¨ë¦¬ì—ì„œ ìµœê·¼ ë°ì´í„° ì²´í¬í•´ì•¼ í•¨
        return False
        
    def _check_machine_alignment(self, numbers: List[int], machine: str) -> bool:
        """í˜¸ê¸° alignment ì²´í¬"""
        personality = self.domain_knowledge['machine_personalities'][machine]
        
        # ê°„ë‹¨í•œ alignment ì²´í¬
        if machine == '3í˜¸ê¸°':
            odd_count = sum(1 for n in numbers if n % 2 == 1)
            return odd_count < 3  # 3í˜¸ê¸°ëŠ” í™€ìˆ˜ë¥¼ ì„ í˜¸í•´ì•¼ í•¨
            
        return False
        
    async def _calculate_cognitive_confidence(self,
                                           numbers: List[int],
                                           machine_type: str,
                                           context_analysis: Dict[str, Any]) -> float:
        """ì¸ì§€ì  ì‹ ë¢°ë„ ê³„ì‚°"""
        
        confidence_factors = []
        
        # 1. ë„ë©”ì¸ ì§€ì‹ ì í•©ì„±
        domain_fitness = self._calculate_domain_fitness(numbers, machine_type)
        confidence_factors.append(domain_fitness * 0.3)
        
        # 2. ì»¨í…ìŠ¤íŠ¸ ì¼ì¹˜ë„
        context_alignment = self._calculate_context_alignment(numbers, context_analysis)
        confidence_factors.append(context_alignment * 0.3)
        
        # 3. ì¸ì§€ ê·œì¹™ í†µê³¼ìœ¨
        rule_compliance = self._calculate_rule_compliance(numbers, machine_type)
        confidence_factors.append(rule_compliance * 0.2)
        
        # 4. ê· í˜• ë° ë‹¤ì–‘ì„± ì ìˆ˜
        balance_score = self._calculate_balance_score(numbers)
        confidence_factors.append(balance_score * 0.2)
        
        return min(max(sum(confidence_factors), 0.0), 1.0)
        
    def _calculate_domain_fitness(self, numbers: List[int], machine_type: str) -> float:
        """ë„ë©”ì¸ ì í•©ì„± ê³„ì‚°"""
        personality = self.domain_knowledge['machine_personalities'][machine_type]
        fitness = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # í˜¸ê¸°ë³„ íŠ¹ì„± í‰ê°€
        if machine_type == '1í˜¸ê¸°' and 'conservative' in personality['traits']:
            total_sum = sum(numbers)
            if 120 <= total_sum <= 180:
                fitness += 0.3
                
        elif machine_type == '2í˜¸ê¸°' and 'harmonious' in personality['traits']:
            # ê· í˜• í‰ê°€
            odd_count = sum(1 for n in numbers if n % 2 == 1)
            if 2 <= odd_count <= 4:
                fitness += 0.3
                
        elif machine_type == '3í˜¸ê¸°' and 'creative' in personality['traits']:
            # ì°½ì˜ì„± í‰ê°€
            odd_count = sum(1 for n in numbers if n % 2 == 1)
            if odd_count >= 4:
                fitness += 0.3
                
        return fitness
        
    def _calculate_context_alignment(self, numbers: List[int], context: Dict[str, Any]) -> float:
        """ì»¨í…ìŠ¤íŠ¸ ì¼ì¹˜ë„ ê³„ì‚°"""
        alignment = 0.5
        
        trends = context['recent_trends']
        
        # íŠ¸ë Œë“œì™€ ì¼ì¹˜ì„± í™•ì¸
        total_sum = sum(numbers)
        
        if trends['sum_trend'] == 'increasing' and total_sum > 140:
            alignment += 0.2
        elif trends['sum_trend'] == 'decreasing' and total_sum < 140:
            alignment += 0.2
            
        return alignment
        
    def _calculate_rule_compliance(self, numbers: List[int], machine_type: str) -> float:
        """ê·œì¹™ ì¤€ìˆ˜ìœ¨ ê³„ì‚°"""
        violations = 0
        total_rules = len(self.cognitive_rules['validation_rules'])
        
        for rule in self.cognitive_rules['validation_rules']:
            if rule['condition'](numbers):
                violations += 1
                
        compliance_rate = (total_rules - violations) / total_rules
        return compliance_rate
        
    def _calculate_balance_score(self, numbers: List[int]) -> float:
        """ê· í˜• ì ìˆ˜ ê³„ì‚°"""
        # í™€ì§ ê· í˜•
        odd_count = sum(1 for n in numbers if n % 2 == 1)
        odd_balance = 1.0 - abs(odd_count - 3) / 3.0
        
        # ê³ ì € ê· í˜•
        high_count = sum(1 for n in numbers if n >= 23)
        high_balance = 1.0 - abs(high_count - 3) / 3.0
        
        # ë¶„ì‚° ê· í˜•
        spread_balance = min(1.0, np.std(numbers) / 15.0)
        
        return (odd_balance + high_balance + spread_balance) / 3.0
        
    async def _generate_prediction_explanation(self,
                                             numbers: List[int],
                                             machine_type: str,
                                             context: Dict[str, Any]) -> Dict[str, Any]:
        """ì˜ˆì¸¡ ì„¤ëª… ìƒì„±"""
        
        explanation = {
            'reasoning_process': [],
            'domain_insights': [],
            'contextual_factors': [],
            'confidence_rationale': []
        }
        
        # ì¶”ë¡  ê³¼ì • ì„¤ëª…
        explanation['reasoning_process'].append(
            f"{machine_type}ì˜ ì„±ê²©ì  íŠ¹ì„±ì„ ë°˜ì˜í•œ ë²ˆí˜¸ ì„ íƒ"
        )
        
        odd_count = sum(1 for n in numbers if n % 2 == 1)
        explanation['reasoning_process'].append(
            f"í™€ì§ ë¹„ìœ¨ {odd_count}:{6-odd_count}ë¡œ ì ì ˆí•œ ê· í˜• ìœ ì§€"
        )
        
        # ë„ë©”ì¸ í†µì°°
        personality = context['machine_personality']
        explanation['domain_insights'].append(
            f"ì„ íƒëœ ì¡°í•©ì´ {machine_type}ì˜ {', '.join(personality['traits'])} íŠ¹ì„±ê³¼ ì¼ì¹˜"
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ìš”ì¸
        trends = context['recent_trends']
        explanation['contextual_factors'].append(
            f"ìµœê·¼ íŠ¸ë Œë“œ ({trends['sum_trend']}, {trends['odd_even_trend']})ë¥¼ ë°˜ì˜"
        )
        
        return explanation
        
    def _extract_key_context_factors(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """í•µì‹¬ ì»¨í…ìŠ¤íŠ¸ ìš”ì¸ ì¶”ì¶œ"""
        return {
            'machine_traits': context['machine_personality']['traits'],
            'trend_summary': context['recent_trends'],
            'seasonal_factor': context['seasonal_factors']['season']
        }
        
    async def _load_domain_knowledge(self):
        """ë„ë©”ì¸ ì§€ì‹ ë¡œë“œ"""
        # ë©”ëª¨ë¦¬ì—ì„œ ê³¼ê±° íŒ¨í„´ ë¡œë“œí•˜ì—¬ ë„ë©”ì¸ ì§€ì‹ ë³´ê°•
        pass
        
    async def _setup_cognitive_rules(self):
        """ì¸ì§€ ê·œì¹™ ì„¤ì •"""
        pass
        
    async def _initialize_explanation_templates(self):
        """ì„¤ëª… í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        self.explanation_templates = {
            'high_confidence': "ë„ë©”ì¸ ì§€ì‹ê³¼ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì„ í†µí•´ ë†’ì€ ì‹ ë¢°ë„ë¡œ ì˜ˆì¸¡",
            'medium_confidence': "ì¼ë¶€ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ì§€ë§Œ ì¶”ê°€ ê²€ì¦ í•„ìš”",
            'low_confidence': "ì œí•œëœ ì •ë³´ë¡œ ì¸í•œ ë¶ˆí™•ì‹¤ì„± ì¡´ì¬"
        }
        
    async def _learn_historical_patterns(self):
        """ê³¼ê±° íŒ¨í„´ í•™ìŠµ"""
        # ê° í˜¸ê¸°ë³„ ê³¼ê±° ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ íŒ¨í„´ ë©”ëª¨ë¦¬ êµ¬ì¶•
        for machine_type in ['1í˜¸ê¸°', '2í˜¸ê¸°', '3í˜¸ê¸°']:
            historical_data = await self.memory_manager.get_lottery_data(
                machine_type=machine_type, limit=50
            )
            
            if historical_data:
                patterns = self._extract_cognitive_patterns(historical_data)
                self.pattern_memory[machine_type] = patterns
                
    def _extract_cognitive_patterns(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì¸ì§€ì  íŒ¨í„´ ì¶”ì¶œ"""
        return {
            'typical_sum_range': [
                np.percentile([r['ì´í•©'] for r in data], 25),
                np.percentile([r['ì´í•©'] for r in data], 75)
            ],
            'common_odd_counts': Counter([
                sum(1 for n in r['1ë“±_ë‹¹ì²¨ë²ˆí˜¸'] if n % 2 == 1) for r in data
            ]).most_common(3),
            'frequent_numbers': Counter([
                n for r in data for n in r['1ë“±_ë‹¹ì²¨ë²ˆí˜¸']
            ]).most_common(10)
        }
        
    async def _validate_with_cognitive_rules(self,
                                           numbers: List[int],
                                           machine_type: str) -> Dict[str, Any]:
        """ì¸ì§€ ê·œì¹™ìœ¼ë¡œ ê²€ì¦"""
        
        validation_result = {
            'passed_rules': [],
            'failed_rules': [],
            'warnings': [],
            'overall_score': 0.0
        }
        
        total_rules = len(self.cognitive_rules['validation_rules'])
        passed_count = 0
        
        for rule in self.cognitive_rules['validation_rules']:
            if not rule['condition'](numbers):
                validation_result['passed_rules'].append(rule['name'])
                passed_count += 1
            else:
                validation_result['failed_rules'].append({
                    'name': rule['name'],
                    'severity': rule['severity'],
                    'message': rule['message']
                })
                
                if rule['severity'] == 'high':
                    validation_result['warnings'].append(rule['message'])
                    
        validation_result['overall_score'] = passed_count / total_rules
        return validation_result
        
    async def _detect_anomalies(self,
                              numbers: List[int],
                              machine_type: str,
                              agent_id: str) -> List[Dict[str, Any]]:
        """ì´ìƒ íƒì§€"""
        anomalies = []
        
        # í†µê³„ì  ì´ìƒ
        total_sum = sum(numbers)
        if total_sum < 50 or total_sum > 250:
            anomalies.append({
                'type': 'statistical_anomaly',
                'description': f'ë¹„ì •ìƒì ì¸ ì´í•©: {total_sum}',
                'severity': 'high'
            })
            
        # íŒ¨í„´ ì´ìƒ
        consecutive_count = self._count_consecutive_numbers(numbers)
        if consecutive_count > 3:
            anomalies.append({
                'type': 'pattern_anomaly',
                'description': f'ê³¼ë„í•œ ì—°ì† ë²ˆí˜¸: {consecutive_count}ê°œ',
                'severity': 'medium'
            })
            
        return anomalies
        
    async def _generate_recommendations(self,
                                      agent_results: Dict[str, Any],
                                      machine_type: str) -> List[Dict[str, Any]]:
        """ì¶”ì²œì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ì—ì´ì „íŠ¸ ê²°ê³¼ê°„ ì¼ê´€ì„± ì²´í¬
        all_predictions = []
        for agent_id, result in agent_results.items():
            if 'predictions' in result:
                all_predictions.extend(result['predictions'])
                
        if len(all_predictions) > 1:
            # ë‹¤ì–‘ì„± ì²´í¬
            unique_numbers = set()
            for pred in all_predictions:
                unique_numbers.update(pred['numbers'])
                
            if len(unique_numbers) < 15:  # ë„ˆë¬´ ì ì€ ë‹¤ì–‘ì„±
                recommendations.append({
                    'type': 'diversity_improvement',
                    'message': 'ì—ì´ì „íŠ¸ ê°„ ì˜ˆì¸¡ ë‹¤ì–‘ì„± ì¦ëŒ€ ê¶Œì¥',
                    'priority': 'medium'
                })
                
        return recommendations
        
    async def _generate_comprehensive_explanations(self,
                                                 agent_results: Dict[str, Any],
                                                 machine_type: str,
                                                 analysis: Dict[str, Any]) -> List[str]:
        """ì¢…í•© ì„¤ëª… ìƒì„±"""
        explanations = []
        
        explanations.append(f"ğŸ§  {machine_type} ì¸ì§€ì  ë¶„ì„ ê²°ê³¼:")
        
        # ì¼ê´€ì„± ìš”ì•½
        consistency_scores = []
        for agent_id, validation in analysis['consistency_check'].items():
            consistency_scores.append(validation['overall_score'])
            
        avg_consistency = np.mean(consistency_scores) if consistency_scores else 0
        explanations.append(f"ğŸ“Š ì „ì²´ ì¼ê´€ì„± ì ìˆ˜: {avg_consistency:.2f}")
        
        # ì´ìƒ íƒì§€ ìš”ì•½
        total_anomalies = sum(len(anomalies) for anomalies in analysis['anomaly_detection'].values())
        if total_anomalies > 0:
            explanations.append(f"âš ï¸  {total_anomalies}ê°œ ì´ìƒ íŒ¨í„´ ê°ì§€ë¨")
        else:
            explanations.append("âœ… ì´ìƒ íŒ¨í„´ ê°ì§€ë˜ì§€ ì•ŠìŒ")
            
        return explanations
        
    async def _generate_meta_analysis(self,
                                    predictions: List[Dict[str, Any]],
                                    machine_type: str,
                                    context_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”íƒ€ ë¶„ì„ ìƒì„±"""
        
        return {
            'prediction_quality': 'high' if all(p['confidence_score'] > 0.7 for p in predictions) else 'medium',
            'context_alignment': 'good',
            'domain_compliance': 'validated',
            'cognitive_insights': [
                f"{machine_type}ì˜ íŠ¹ì„±ì´ ì˜ˆì¸¡ì— ì ì ˆíˆ ë°˜ì˜ë¨",
                "ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ê²€ì¦ í†µê³¼",
                "ì»¨í…ìŠ¤íŠ¸ ìš”ì¸ë“¤ì´ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤ë¨"
            ]
        }