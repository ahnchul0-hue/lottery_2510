# ğŸ¤– Next-Generation Hive-Mind Lottery Prediction System
# FastAPI backend with advanced agent spawning and orchestration

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
import asyncio
import logging
import uuid
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import json
import uvicorn

from pydantic import BaseModel, Field

# Hive-Mind Components
from hive_mind.orchestrator import QueenOrchestrator
from hive_mind.config import get_config, get_config_manager
from hive_mind.memory import MemoryManager
from hive_mind.communication import MessageBus

# API Models
class PredictionRequest(BaseModel):
    """ì˜ˆì¸¡ ìš”ì²­ ëª¨ë¸"""
    machine_type: str = Field(..., description="ë¡œë˜ ê¸°ê³„ ìœ í˜• (1í˜¸ê¸°, 2í˜¸ê¸°, 3í˜¸ê¸°)")
    sets_count: int = Field(default=1, ge=1, le=5, description="ì˜ˆì¸¡ ì„¸íŠ¸ ìˆ˜")
    algorithm: str = Field(default="hybrid", description="ì‚¬ìš©í•  ì•Œê³ ë¦¬ì¦˜")
    ensemble_strategy: str = Field(default="dynamic", description="ì•™ìƒë¸” ì „ëµ")
    historical_data: Optional[List[Dict]] = Field(default=None, description="ì¶”ê°€ ê³¼ê±° ë°ì´í„°")
    
class PredictionResponse(BaseModel):
    """ì˜ˆì¸¡ ì‘ë‹µ ëª¨ë¸"""
    success: bool
    predictions: List[Dict[str, Any]]
    confidence_scores: List[float]
    processing_time_ms: float
    machine_type: str
    algorithm_used: str
    system_info: Dict[str, Any]
    
class SystemHealthResponse(BaseModel):
    """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ì‘ë‹µ"""
    status: str
    health_score: int
    uptime_seconds: float
    active_agents: int
    message_bus_health: Dict[str, Any]
    memory_usage: Dict[str, Any]
    performance_metrics: Dict[str, Any]
    
class AgentStatusResponse(BaseModel):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ì‘ë‹µ"""
    agents: List[Dict[str, Any]]
    total_count: int
    active_count: int
    
# Global system components
app_state = {
    'orchestrator': None,
    'memory_manager': None,
    'message_bus': None,
    'startup_time': None
}

# Security
security = HTTPBearer(auto_error=False)

async def get_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """API í‚¤ ê²€ì¦"""
    config = get_config()
    
    if not config.api.api_key_required:
        return None
        
    if not credentials:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="API key required"
        )
        
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ API í‚¤ ê²€ì¦
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ê²€ì¦ ë¡œì§
    if credentials.credentials != config.api.jwt_secret:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid API key"
        )
        
    return credentials.credentials

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬"""
    # Startup
    logging.info("ğŸš€ Starting Hive-Mind Lottery Prediction System")
    
    try:
        # ì„¤ì • ë¡œë“œ
        config_manager = get_config_manager()
        config = config_manager.get_config()
        
        # ë¡œê·¸ ì„¤ì •
        logging.basicConfig(
            level=getattr(logging, config.monitoring.log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™”
        memory_manager = MemoryManager(config.to_dict())
        await memory_manager.initialize()
        app_state['memory_manager'] = memory_manager
        
        # ë©”ì‹œì§€ ë²„ìŠ¤ ì´ˆê¸°í™”
        message_bus = MessageBus(config.message_bus.to_dict())
        await message_bus.start()
        app_state['message_bus'] = message_bus
        
        # Queen Orchestrator ì´ˆê¸°í™”
        orchestrator = QueenOrchestrator(
            orchestrator_id="queen_main",
            config=config.to_dict(),
            memory_manager=memory_manager,
            message_bus=message_bus
        )
        await orchestrator.initialize()
        app_state['orchestrator'] = orchestrator
        
        app_state['startup_time'] = datetime.now()
        
        logging.info("âœ… Hive-Mind system started successfully")
        
        yield
        
    except Exception as e:
        logging.error(f"âŒ Failed to start Hive-Mind system: {e}")
        raise
        
    # Shutdown
    logging.info("ğŸ”„ Shutting down Hive-Mind system")
    
    try:
        if app_state['orchestrator']:
            await app_state['orchestrator'].shutdown()
            
        if app_state['message_bus']:
            await app_state['message_bus'].stop()
            
        if app_state['memory_manager']:
            await app_state['memory_manager'].close()
            
        logging.info("âœ… Hive-Mind system shutdown completed")
        
    except Exception as e:
        logging.error(f"âŒ Error during shutdown: {e}")

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
app = FastAPI(
    title="Next-Generation Hive-Mind Lottery Prediction System",
    description="Advanced AI system for lottery prediction using hybrid ML and distributed agent architecture",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
config = get_config()
app.add_middleware(
    CORSMiddleware,
    allow_origins=config.api.cors_origins,
    allow_credentials=True,
    allow_methods=config.api.cors_methods,
    allow_headers=config.api.cors_headers,
)

# API ì—”ë“œí¬ì¸íŠ¸ë“¤

@app.get("/", response_model=Dict[str, Any])
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "service": "Next-Generation Hive-Mind Lottery Prediction System",
        "version": "1.0.0",
        "status": "operational",
        "documentation": "/docs",
        "health": "/api/monitoring/health"
    }

@app.post("/api/predictions/generate", response_model=PredictionResponse)
async def generate_predictions(
    request: PredictionRequest,
    background_tasks: BackgroundTasks,
    api_key: Optional[str] = Depends(get_api_key)
):
    """ë¡œë˜ ë²ˆí˜¸ ì˜ˆì¸¡ ìƒì„±"""
    start_time = datetime.now()
    
    try:
        orchestrator = app_state['orchestrator']
        if not orchestrator:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="System not initialized"
            )
            
        # ì˜ˆì¸¡ ìš”ì²­ ë°ì´í„° ì¤€ë¹„
        task_data = {
            'request_id': str(uuid.uuid4()),
            'machine_type': request.machine_type,
            'sets_count': request.sets_count,
            'algorithm': request.algorithm,
            'ensemble_strategy': request.ensemble_strategy,
            'historical_data': request.historical_data,
            'timestamp': datetime.now().isoformat()
        }
        
        # ì˜ˆì¸¡ ìƒì„±
        result = await orchestrator.generate_predictions(task_data)
        
        if not result.get('success'):
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Prediction failed: {result.get('error', 'Unknown error')}"
            )
            
        processing_time = (datetime.now() - start_time).total_seconds() * 1000
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥
        background_tasks.add_task(
            _save_prediction_metrics,
            task_data,
            result,
            processing_time
        )
        
        return PredictionResponse(
            success=True,
            predictions=result.get('predictions', []),
            confidence_scores=result.get('confidence_scores', []),
            processing_time_ms=processing_time,
            machine_type=request.machine_type,
            algorithm_used=result.get('algorithm_used', request.algorithm),
            system_info={
                'agents_used': result.get('agents_used', []),
                'consensus_score': result.get('consensus_score', 0),
                'model_versions': result.get('model_versions', {})
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"âŒ Prediction generation failed: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Internal server error during prediction"
        )

@app.post("/api/ensemble/predictions/")
async def generate_ensemble_predictions(
    request: Dict[str, Any],
    background_tasks: BackgroundTasks,
    api_key: Optional[str] = Depends(get_api_key)
):
    """ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„± (ê³ ê¸‰ ì˜µì…˜)"""
    try:
        orchestrator = app_state['orchestrator']
        
        # ë‹¤ì¤‘ ì•™ìƒë¸” ì „ëµìœ¼ë¡œ ì˜ˆì¸¡
        strategies = request.get('strategies', ['voting', 'stacking', 'blending', 'dynamic'])
        results = {}
        
        for strategy in strategies:
            task_data = {
                **request,
                'ensemble_strategy': strategy,
                'request_id': f"{str(uuid.uuid4())}_{strategy}"
            }
            
            result = await orchestrator.generate_predictions(task_data)
            results[strategy] = result
            
        return {
            'success': True,
            'ensemble_results': results,
            'recommended_strategy': await _determine_best_strategy(results),
            'processing_info': {
                'strategies_used': len(strategies),
                'total_predictions': sum(len(r.get('predictions', [])) for r in results.values())
            }
        }
        
    except Exception as e:
        logging.error(f"âŒ Ensemble prediction failed: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Ensemble prediction failed"
        )

@app.get("/api/agents/status", response_model=AgentStatusResponse)
async def get_agents_status(api_key: Optional[str] = Depends(get_api_key)):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ì¡°íšŒ"""
    try:
        orchestrator = app_state['orchestrator']
        if not orchestrator:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="System not initialized"
            )
            
        agents_info = await orchestrator.get_agents_status()
        
        return AgentStatusResponse(
            agents=agents_info.get('agents', []),
            total_count=agents_info.get('total_count', 0),
            active_count=agents_info.get('active_count', 0)
        )
        
    except Exception as e:
        logging.error(f"âŒ Failed to get agents status: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve agents status"
        )

@app.post("/api/agents/spawn/{agent_type}")
async def spawn_agent(
    agent_type: str,
    config: Optional[Dict[str, Any]] = None,
    api_key: Optional[str] = Depends(get_api_key)
):
    """ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ ìƒì„±"""
    try:
        orchestrator = app_state['orchestrator']
        
        result = await orchestrator.spawn_agent(agent_type, config or {})
        
        if result.get('success'):
            return {
                'success': True,
                'agent_id': result['agent_id'],
                'agent_type': agent_type,
                'message': f"Agent {agent_type} spawned successfully"
            }
        else:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Failed to spawn agent: {result.get('error')}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"âŒ Agent spawning failed: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Agent spawning failed"
        )

@app.delete("/api/agents/{agent_id}")
async def terminate_agent(
    agent_id: str,
    api_key: Optional[str] = Depends(get_api_key)
):
    """ì—ì´ì „íŠ¸ ì¢…ë£Œ"""
    try:
        orchestrator = app_state['orchestrator']
        
        result = await orchestrator.terminate_agent(agent_id)
        
        if result.get('success'):
            return {
                'success': True,
                'message': f"Agent {agent_id} terminated successfully"
            }
        else:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Agent not found: {agent_id}"
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"âŒ Agent termination failed: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Agent termination failed"
        )

@app.get("/api/statistics/machine-analysis/{machine_type}")
async def get_machine_analysis(
    machine_type: str,
    api_key: Optional[str] = Depends(get_api_key)
):
    """ê¸°ê³„ë³„ í†µê³„ ë¶„ì„"""
    try:
        memory_manager = app_state['memory_manager']
        
        # ê³¼ê±° ì˜ˆì¸¡ ë°ì´í„° ì¡°íšŒ
        historical_predictions = await memory_manager.get_prediction_history(
            filters={'machine_type': machine_type},
            limit=100
        )
        
        # í†µê³„ ê³„ì‚°
        stats = {
            'machine_type': machine_type,
            'total_predictions': len(historical_predictions),
            'avg_confidence': 0.0,
            'number_frequency': {},
            'pattern_analysis': {},
            'recent_performance': {}
        }
        
        if historical_predictions:
            # ì‹ ë¢°ë„ í‰ê· 
            confidences = [p.get('confidence', 0) for p in historical_predictions]
            stats['avg_confidence'] = sum(confidences) / len(confidences)
            
            # ë²ˆí˜¸ ë¹ˆë„
            all_numbers = []
            for pred in historical_predictions:
                for prediction_set in pred.get('predictions', []):
                    all_numbers.extend(prediction_set.get('numbers', []))
                    
            for num in range(1, 46):
                stats['number_frequency'][str(num)] = all_numbers.count(num)
                
        return stats
        
    except Exception as e:
        logging.error(f"âŒ Machine analysis failed: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Machine analysis failed"
        )

@app.get("/api/monitoring/health", response_model=SystemHealthResponse)
async def get_system_health():
    """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ì¡°íšŒ"""
    try:
        orchestrator = app_state['orchestrator']
        message_bus = app_state['message_bus']
        memory_manager = app_state['memory_manager']
        startup_time = app_state['startup_time']
        
        if not all([orchestrator, message_bus, memory_manager, startup_time]):
            return SystemHealthResponse(
                status="unhealthy",
                health_score=0,
                uptime_seconds=0,
                active_agents=0,
                message_bus_health={},
                memory_usage={},
                performance_metrics={}
            )
            
        # ì—…íƒ€ì„ ê³„ì‚°
        uptime = (datetime.now() - startup_time).total_seconds()
        
        # ê° ì»´í¬ë„ŒíŠ¸ ìƒíƒœ
        orchestrator_health = await orchestrator.get_system_health()
        message_bus_health = message_bus.get_system_health()
        memory_health = await memory_manager.get_health_status()
        
        # ì „ì²´ ê±´ê°• ì ìˆ˜ ê³„ì‚°
        health_scores = [
            orchestrator_health.get('health_score', 0),
            message_bus_health.get('health_score', 0),
            memory_health.get('health_score', 0)
        ]
        
        overall_health = sum(health_scores) / len(health_scores) if health_scores else 0
        
        status = "healthy" if overall_health >= 80 else "degraded" if overall_health >= 60 else "unhealthy"
        
        return SystemHealthResponse(
            status=status,
            health_score=int(overall_health),
            uptime_seconds=uptime,
            active_agents=orchestrator_health.get('active_agents', 0),
            message_bus_health=message_bus_health,
            memory_usage=memory_health,
            performance_metrics={
                'avg_prediction_time_ms': orchestrator_health.get('avg_prediction_time', 0),
                'total_predictions': orchestrator_health.get('total_predictions', 0),
                'success_rate': orchestrator_health.get('success_rate', 0)
            }
        )
        
    except Exception as e:
        logging.error(f"âŒ Health check failed: {e}")
        return SystemHealthResponse(
            status="error",
            health_score=0,
            uptime_seconds=0,
            active_agents=0,
            message_bus_health={"error": str(e)},
            memory_usage={},
            performance_metrics={}
        )

@app.get("/api/monitoring/metrics")
async def get_system_metrics(api_key: Optional[str] = Depends(get_api_key)):
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        orchestrator = app_state['orchestrator']
        message_bus = app_state['message_bus']
        
        metrics = {
            'orchestrator_metrics': await orchestrator.get_performance_metrics() if orchestrator else {},
            'message_bus_metrics': message_bus.get_metrics() if message_bus else {},
            'timestamp': datetime.now().isoformat()
        }
        
        return metrics
        
    except Exception as e:
        logging.error(f"âŒ Metrics retrieval failed: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve metrics"
        )

# Helper functions

async def _save_prediction_metrics(task_data: Dict, result: Dict, processing_time: float):
    """ì˜ˆì¸¡ ë©”íŠ¸ë¦­ ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)"""
    try:
        memory_manager = app_state['memory_manager']
        if memory_manager:
            await memory_manager.store_prediction_log({
                **task_data,
                'result': result,
                'processing_time_ms': processing_time,
                'completed_at': datetime.now().isoformat()
            })
    except Exception as e:
        logging.error(f"âŒ Failed to save prediction metrics: {e}")

async def _determine_best_strategy(results: Dict[str, Any]) -> str:
    """ìµœì  ì•™ìƒë¸” ì „ëµ ê²°ì •"""
    try:
        # ê° ì „ëµì˜ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        strategy_scores = {}
        
        for strategy, result in results.items():
            if result.get('success'):
                confidences = result.get('confidence_scores', [])
                if confidences:
                    strategy_scores[strategy] = sum(confidences) / len(confidences)
                    
        # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ì „ëµ ë°˜í™˜
        if strategy_scores:
            return max(strategy_scores, key=strategy_scores.get)
        else:
            return "dynamic"  # ê¸°ë³¸ê°’
            
    except Exception:
        return "dynamic"

# ì—ëŸ¬ í•¸ë“¤ëŸ¬
@app.exception_handler(404)
async def not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={
            "error": "Not Found",
            "message": "The requested resource was not found",
            "path": str(request.url.path)
        }
    )

@app.exception_handler(500)
async def internal_error_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal Server Error",
            "message": "An internal server error occurred",
            "timestamp": datetime.now().isoformat()
        }
    )

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    config = get_config()
    
    uvicorn.run(
        "main:app",
        host=config.api.host,
        port=config.api.port,
        workers=1,  # ë‹¨ì¼ ì›Œì»¤ (ë©€í‹°í”„ë¡œì„¸ì‹± ì‹œ ìƒíƒœ ê³µìœ  ì´ìŠˆ ë°©ì§€)
        reload=config.debug,
        log_level=config.monitoring.log_level.lower()
    )